---
id: multithreading
aliases:
  - mt
tags: []
---

# Base terms

> Многопоточность была ещё в ПЭВМ (ПК), где был всего 1 процессор (и 1 поток). 
> Как она реализовывалась? - был некоторый механизм, который в какие-то моменты времени переключался на другую задачу, быстренько просматривался статус или ещё что-то и происходило переключение обратно.

- Подобного рода имитация параллельности можно именовать как **псевдопараллельное выполнение**.
- **Многозадачность** - способность среды выполнять параллельно или псевдопараллельно (например асинхронщина) несколько задач
- **Многопоточность** - способность окружения выполнять в одном контексте несколько задач параллельно за счёт использования нескольких потоков
- **Процесс** - некоторая программа, которая может содержать в себе:
    - потоки
    - открытые дескрипторы (сокеты, файлы и т.п.)
    - дочерние процессы
    - адресное пространство
    - и т.п.

	
## **Поток**
> В контекста программирования: поток - *независимая последовательность выполнения инструкций внутри одного процесса с общей памятью, но собственными регистрами и стеком*.
- Каждый поток имеет *собственные*:
    - стэк
    - регистры
    - thread local storage

- Но вот *потоки одного процесса* разделяют общее:
    - адресное пространство
    - глобальные переменные
    - кучу

## Race condition
> Ситуация, когда несколько потоков пытаются сделать Read или Write на ресурсы без согласования порядка операций.
> Выходит, что "кто успел, тот и получил"
```go
func main() {
	var taken atomic.Bool
	var wg sync.WaitGroup

	worker := func(id int) {
		defer wg.Done()

		// Пытаемся "захватить" задачу
        // CompareAndSwap(a, b) -> если atomic == a, тогда swap происходит
		if taken.CompareAndSwap(false, true) {  
			fmt.Println("Worker", id, "got the task")
		}
	}

	wg.Add(2)
	go worker(1)
	go worker(2)

	wg.Wait()
    // output -> наугад либо 1-ый воркер успел, либо 2-ой...
}
```

## Data race
> "Состояние гонки" - ситуация.. да вообще почти то же самое, что и race condition, только здесь нарушается модель доступа к данным, а не к логика и порядок операций.
```cpp
int x = 0;

void t1() { x = 1; }
void t2() { x = 2; }
// тут data race, т.к. меняем данные без некоторого "happens before"
// хотя и race condition, т.к. и не знаем, что получим в итоге.. 1 или 2
```

```cpp
std::atomic<int> x{0};

void t1() { x.store(1); }
void t2() { x.store(2); }
// тут мы исправили атомиком data race, теперь переменную гарантированно меняют в некотором порядке
// ну тут всё ещё race condition, т.к. мы не знаем, что получим в итоге.. 1 или 2
```


# Sync primitives
> без специальных механизмов синхронизации у нас нет никакой возможности узнать, какой поток какое состояние имеет в данный момент времени или же, что он выполняет

## mutex

> Мне нравится аналогия с "описателем блокировки", хотя под капотом это некоторый особый объект с 2 состояниями: 0, 1.
> * технически ещё внутри иногда есть информация о владельце, о кол-ве ожидающих потоков и т.п.

- какой-то из потоков зашёл в код, переключил мьютекс на “используется”
    - на самом деле поток попытался сделать Compare-and-swap (CAS) операцию по смене мьютекса с 0 -> 1
        - если получилось -> круто (fast path)
- другие потоки зашли в код, спросили “занят ли кем-то мьютекс"
    - они тоже попытались сделать CAS, но операция не получилась
- ждут пока мьютекс “освободят"
    - CAS не вышел -> поток уходит в ожидание и менеджится там планировщиком ОС (slow path)
- когда мьютекс освобождается → какой-то следующий 1 поток успевает залететь
- ... всё по новой

- lock()
    > Захватывает поток, т.е. поток, который вызывает этот метод, имеет эксклюзивные права на выполнение кода, другие потоки не имеют права вмешиваться.
    > Мне нравится ассоциировать "захват мьютекса" с conquere area или capture flag =)
- unlock()
    > Противоположно lock(), освобождает поток от захвата.

```cpp
mutex mtx;                         // Описатель взаимной блокировки
int number = 0; 
  
void Increment()
{ 
    mtx.lock();                         // сюда зайдут и t1 и t2, но мы не знаем точно кто и когда
    
    for (int i = 0; i < 1000000; i++)
    { 
        number++;                       // какая-то операция на изменение данных
    } 
      
    mtx.unlock();                       // поток, что успел выполнить код, позволяет другому сделать своё дело
} 
  
int main() 
{ 
    thread t1(Increment); 
    thread t2(Increment); 
      
    // это просто "ожидаем, пока все потоки закончат свою работу" *
    t1.join(); 
    t2.join(); 
      
    cout << "Number after execution of t1 and t2 is "<< number; 
      
    return 0; 
} 
```

### mutex/lock granularity
> Это концепция, описывающая, объём кода, защищённых мьютексом…

#### Coarse-grained locking
> При грубой гранулярности мьютекс защищает огромный кусок кода

```cpp
mutex mtx;
array<int, 1000> accounts;

void Transfer(size_t to, size_t from, int amount) 
{
    mtx.lock();
    
    if (accounts[from] < amount) 
    {
        m.unlock();
        throw runtime_error("insufficient funds");
    }
    
    accounts[from] -= amount;
    accounts[to]   += amount;
    
    mtx.unlock();
}
```

Может значительно уменьшить производительность в многопоточных приложениях, поскольку потоки вынуждены ждать друг друга, даже если они работают с разными частями данных. Однако код куда проще понять и контроллировать.

#### Fine-grained locking
> При тонкой гранулярности используется несколько мьютексов, защищающих как можно меньшие куски кода…

```cpp
struct account {
    mutex       mtx;
    int32_t     balance;
};

// в других ЯП это почти обычный lock
using lock_guard_t = lock_guard<mutex>;

array<account, 1000> accounts;

void Transfer(size_t to, size_t from, int amount) 
{
    lock_guard_t lg_from(accounts[from].mtx);
    lock_guard_t lg_to(accounts[to].mtx);
    
    if (accounts[from].balance < amount) 
    {
        throw runtime_error("insufficient funds");
    }
    
    accounts[from].balance -= amount;
    accounts[to].balance   += amount;
}
```

Может значительно улучшить производительность за счёт лучшей параллелизации, но цена этого — усложнение кода и потенциальные проблемы с синхронизацией, такие как deadlock.

### Misc
> Есть 3 специальные инструкции процессора, которые в этом теме фигурируют:
- CAS -> Compare-and-swap
- FAA -> Fetch-and-add
- TAS -> Test-and-set


## atomic
> Это специальный объект, воплощающий специальные инструкции атомарности для указанного передаваемого объекта.

>Атомарная операция - некоторая неделимая операция, промежуточнное состояние которой другие потоки не способны увидеть.

Т.е. разные потоки не могут видеть промежуточный результат выполнения какого-нибудь, условно, сложения, они могут видеть только “начальное состояние” и “конечный результат”.

> Инструкции по обеспечения атомарности для процессора зависят от архитектуры. В разных архитектурах атомарность описана по-разному.

### Problem

```go
func main() {
    var counter int64
    var wg sync.WaitGroup

    // Launch 1000 goroutines to increment concurrently
    for i := 0; i < 1000; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            // Atomic addition
            atomic.AddInt64(&counter, 1)
        }()
    }
    wg.Wait()
    fmt.Println("Counter:", atomic.LoadInt64(&counter)) // Output: 1000
}
```

> Представим код выше без атомика...
- 1000 асинк тасков (синтаксически речь про `go`)
- все делают "+1", само по себе это "прочитать значение" + "добавить единицу" - т.е. не атомарно...
- несколько потоков одновременно могут, например, прочитать 44 и все сделают +1
- в итоге все 3 потока сделали работу по 44 + 1, вместо задуманного 44 + 1 + 1 + 1
- а это прям Race Condition был бы

### A bit low lvl...

```cpp
static int v1 = 0;
static atomic<int> v2 { 0 };

int add_v1() 
{
    return ++v1;
    /* Generated x86-64 assembly:
        mov     eax, DWORD PTR v1[rip]       -> read
        add     eax, 1                       -> modify
        mov     DWORD PTR v1[rip], eax       -> write
    */
    // Т.е.  в этом цилке операций read-modify-write, может вдруг выполниться
    // другой поток, что в целом приведёт к UB
}

int add_v2() 
{
    return v2.fetch_add(1);
    /* Generated x86-64 assembly:
        mov        eax, 1                               -> only modify
        lock xadd  DWORD PTR _ZL2v2[rip], eax
        ! Операция lock представляет собой гарантию на уровне процессоров
        ! что к текущей кэш линии, где лежит v2, может обратиться только 1 ядро
        ! * Кэш линия - просто система кэширования данных в процессоре
        ! * * линию здесь можно ассоциировать с конвеером закэшированных данных
    */
}
```

## condition variable
> Определённый примитив стандарта, позволяющий пробуждать потоки при выполнении “определённого условия”.

```cpp
mutex m;
condition_variable cv; // <-- !
string data;

bool ready = false; // The shared condition flag


void consumer_thread() {
    // ~ mutex.lock()
    unique_lock<mutex> lk(m);

    //
    // Блокируемся и ждём пока `ready` не станет true...
    // конкретно в этом ЯП мы должны передать `*_lock`, 
    // .. но глобально cv обязан пользоваться каким-либо описателем блокировки
    //
    cv.wait(lk, []{ return ready; });

    cout << "Consumer thread is processing data: " << data << endl;
    // ~ mutex.unlock()
}


void producer_thread() {
    this_thread::sleep_for(chrono::seconds(1));

    {
        // ~ mutex.lock()
        lock_guard<mutex> lk(m);

        data = "Sample data";
        ready = true;
        cout << "Producer thread signals data is ready" << endl;
        // ~ mutex.unlock()
    }

    //
    // оповещаем один случайный поток, что он может продолжить, а не стоять на wait()
    //
    cv.notify_one();
}


int main() {
    thread consumer(consumer_thread);
    thread producer(producer_thread);

    consumer.join();
    producer.join();

    return 0;
}
```

У него есть несколько значимых функций:
- wait - поток начинает спать
- notify_one - пробуждает один поток
    - Пробуждает только тот 1 поток, который вызвал  wait(), какой именно из пачки потоков будет выбран - неизвестно, стандарт ничего в этом случае явно не гарантирует
- notify_all - пробуждает все потоки (все ожидающие потоки, у которых есть wait)
* `wait` принимает в качестве аргумента `unique_lock`. Это нужно, чтобы между `unlock` и вызовом `wait` другой поток ничего не испортил. 

### Tips
- у condition variable есть проблема с таким явлением как *spurioues wakeups* == "случайно может проснуться"
    - самый дефолт пример - cv + любой асинк механизм ОС

## semaphore
> разрешает лишь нескольким потокам смотреть на критическую секцию

### counting
 > как и задумано... хранит внутри себя **счётчик**!

* инитится семафор с кол-вом потоков, которым будет доступен ресурс
* `wait()` или `acquire()`:
	* если счётчик уже 0, то текущий поток блокируется, пока он не станет равным 0
	* если счётчик не 0, то текущий поток попадает в крит. секцию и тогда счётчик уменьшается на 1
* `release()` или `post()` - выходи из критической секциии и увеличивают счётчик на 1

```cpp
counting_semaphore<2> semaphore(2); 

void worker_function(int id) {
    semaphore.acquire();
	
    this_thread::sleep_for(chrono::seconds(1)); 
	
    semaphore.release();
}

int main() {
    thread t1(worker_function, 1);
    thread t2(worker_function, 2);
    thread t3(worker_function, 3);
    thread t4(worker_function, 4);

    t1.join();
    t2.join();
    t3.join();
    t4.join();

    return 0;
}
```
### binary
> смысл тот же, только у нас всего 1 поток...
> суть семафора в таком случае - просигнализировать из другого потока, что мы можем зайти в критическую секцию

- фактически это замена:
	- mutex + condition variable (он просто не всегда во всях яп или ос ок с сигналами)
	- spinlock + atomic
	
```cpp
// 0 (non-signaled state initially)
binary_semaphore prepareSignal(0);

vector<int> myVec{};

void prepareWork() {
    myVec.insert(myVec.end(), {0, 1, 0, 3});
    cout << "Sender: Data prepared.\n";
	
    prepareSignal.release(); // POST
}

void completeWork() {
    cout << "Waiter: Waiting for data.\n";
	
    prepareSignal.acquire(); // WAIT
    
    myVec[2] = 2; // Modify the shared data
    cout << "Waiter: Complete the work. Data: ";
}

int main() {
    thread t1(prepareWork);
    thread t2(completeWork);

    t1.join();
    t2.join();

    return 0;
}
```

# Common problems

## Volatile
> Ключевое слово.. Есть в нескольких ЯП и везде работает по-разному, где-то это вообще не связано с многопоточкой (С++/Arduino), а где-то наоборот имеет прямое отношение к ней (Java/С#).
> Be careful

## deadlock
> Это ситуация, когда два потока пытаются захватить два мьютекса в разном порядке, из-за чего могут заблокировать друг друга. Лучше посмотреть пример:

```cpp
mutex mtx1;
mutex mtx2;

void thread1() 
{
    lock_guard<mutex> lock1(mtx1);
    this_thread::sleep_for(50ms);       		// Имитация работы

    //
    // Поток 1 пытается захватить mtx2, но он уже захвачен потоком 2, 
    // поэтому поток 1 блокируется, ожидая освобождения mtx2
    //
    lock_guard<mutex> lock2(mtx2);

    cout << "Thread 1 has locked both mutexes.\n";
}

void thread2() 
{
    lock_guard<mutex> lock1(mtx2);
    this_thread::sleep_for(50ms);       		// Имитация работы

    //
    // Поток 2 пытается захватить mtx1, но он уже захвачен потоком 1, 
    // поэтому поток 2 блокируется, ожидая освобождения mtx1
    //
    lock_guard<mutex> lock2(mtx1);

    cout << "Thread 2 has locked both mutexes.\n";
}

int main() 
{
    thread t1(thread1);
    thread t2(thread2);
    
    //
    // В итоге оба потока ждут освобождения друг друга
    // т.е. они друг друга заблокировали...
    //

    t1.join();
    t2.join();

    return 0;
}
```

- Решение? -> Локать их строго в одном порядке (в одном 1-2, в другом тоже 1-2 вместо 2-1)
    - обычно для такого есть отдельные типы в ЯП, где они сами на себя эту обязанность берут

## Livelock
> Похожая ситуация на deadlock, только оба (например..) потока друг другу уступают или мешают постоянно, а не блокируют.
> А ещё похоже на "прогресса нет, но и потоки не заблокированы"

```go
var mu1 sync.Mutex
var mu2 sync.Mutex

func worker1() {
    for {
        mu1.Lock()

        if mu2.TryLock() {
            // ... работа
            mu2.Unlock()

            mu1.Unlock()
            return
        }
        mu1.Unlock()
        // "вежливо" отступаем и пробуем снова
    }
}

func worker2() {
    for {
        mu2.Lock()

        if mu1.TryLock() {
            // ... работа
            mu1.Unlock()

            mu2.Unlock()
            return
        }
        mu2.Unlock()
    }
}
```

- w1 локает m1, w2 локает m2
- w1 пытается взять m2, который залокан, не получается, похожая ситуация у w2 с m1
- оба анлокаются и снова по новой
- в итоге оба потока не заблокированы, но не дают друг другу сделать свою задачу

# Spinlock
> Методология поверх механизмов синхронизации
> Работает по принципу “while(true) { спим? → да → крутимся дальше } … { спим? → Неа, вставай давай → выход из while(true) → делаем дело”

- Не забываем, что такое “активное ожидание” удерживает процессорное время в этом потоке, ну т.е. в этом потоке процессор только ждёт и всё.

```cpp
class spinlock final
{
    atomic_flag locked = ATOMIC_FLAG_INIT;
    
public:
    void lock() 
    {
        //
        // Пытаемся установить флаг, пока он уже установлен
        //
        
        while (locked.test_and_set(memory_order_acquire))
        {
            // активное ожидание, "крутимся", пока флаг не освободится
        }
    }

    void unlock() 
    {
        locked.clear(memory_order_release);  // Освобождаем флаг
    }
};
```

Использовать лишь когда:
- Ожидается, что блокировка будет удерживаться **очень короткий промежуток времени** (например, несколько инструкций).
- Затраты на переключение контекста (например, при использовании обычного мьютекса, который может переводить поток в состояние ожидания) выше, чем затраты на "кручение" в цикле.
    - (если ожидается, что блокировка будет освобождена почти мгновенно, то затраты на ожидание через спинлок могут оказаться ниже, чем затраты на переход потока в спящий режим и его последующее пробуждение)
    - * mutex усыпляет поток, а spinlock заставляет процессор “активно ждать”

# Lock-free структуры
> Это специальные структуры данных для синхронизации, которые не используют мьютексы, не блокируют ничего явно. 
> Он строятся строго на "попытайся локнуть, добавить, прочитать..."
- Тут часто фигурируют CAS, FAA, TAS, atomic и т.п.
- spinlock похож на это всё, но он всё же блокирует, поэтому... нет...

```cpp
struct Node {
    int   v;
    Node* next;
};


atomic<Node*> head{nullptr};


void push(int x) {
    auto* n = new Node{x, nullptr};                // создаём новую ноду
    auto* old = head.load(memory_order_relaxed);   // выгружаем себе в old старую

    do {
        n->next = old;                      // связываем с текущей головой
        //
        // теперь, пытаемся сделать head = n, но только если head всё ещё old
        // * memory order это строго махинации С++ с порядком операций, на суть здесь не влияет
        //
    } while (!head.compare_exchange_weak(
        old, n,
        memory_order_release,
        memory_order_relaxed
    ));
}
```

# Wait-free структуры
> Структуры данных, где гарантируется, что поток завершит операцию за ограниченное число шагов...
- Самый стандартный случай - atomic
- дальше я хз...

# Misc
> Вещи, которые оч похожи, но философски ничего нового...
    - Events (Windows) - подобие бинарного семафора с использованием объекта ядра и фишками с ресетом событий
    - Signals (Unix) - это вообще асинхронный контекст для управления процессом.. в unix Ctrl + c асинхронный, например...
    - Futex (Linux) - Fast Userspace Mutex, просто шустрый мьютекс, который работает не в kernel пока нет конкуренции
    - Barrier - N-потоков должны дойти до одной точки, а потом продолжить выполнение вместе
